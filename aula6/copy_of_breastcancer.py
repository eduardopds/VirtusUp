# -*- coding: utf-8 -*-
"""Copy of BreastCancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N_kCobcRVsQL2Cx2Y7zlFlRNt4V3CVYm

#Treinando e avaliando Árvores de Decisão e Redes Neurais em dados de tumores da mama

https://www.kaggle.com/paultimothymooney/predicting-breast-cancer-from-nuclear-shape

https://medium.com/analytics-vidhya/creating-a-machine-learning-model-to-predict-malignant-breast-cancer-tumors-87abc4065432

https://scikit-learn.org/stable/modules/tree.html

O núcleo é uma organela presente em todas as células eucarióticas, incluindo células humanas. A forma nuclear irregular pode ser usada para identificar células cancerígenas. Artigos científicos sugerem que há alguma conexão entre a forma do núcleo e os estados de doenças humanas, como câncer e envelhecimento. Como tal, a análise quantitativa do tamanho e forma nuclear tem importantes aplicações biomédicas.

Técnicos podem usar um microscópio para observar amostras de tecido que foram retiradas de pacientes com suspeita de câncer de mama. Observando o tamanho e a forma dos núcleos presentes nessas amostras de tecido, os médicos podem determinar se uma determinada amostra parece ser benigna ("B") ou maligna ("M"). Seria bom ter um método automatizado que possa determinar rapidamente se uma amostra é benigna ou maligna. Neste notebook é demonstrado o uso de árvore de decisão e uma rede neural multicapara para prever a classe de uma amostra de tecido, dadas as medidas dos núcleos das células encontradas.

##Setup

First, we must setup our environment. We import various libraries (which you can view in the code cell below) and setup our directories according to the result we get from walking the filenames in our supplied files.
"""

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.model_selection import train_test_split # splitting our data into training and testing data
import seaborn as sns # for creating a correlation heatmap
import matplotlib.pyplot as plt # for displaying our heatmap for analysis
from sklearn.metrics import accuracy_score # to score our model
from sklearn import tree
from sklearn.neural_network import MLPClassifier

# Input data files are available in the "../input/" directory.

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""##Reading our Data

Here, we read our data from the supplied .csv file using Pandas and representing it as a Pandas dataframe.

We are interested in predicting a diagnosis based on cell features, so we assign a 'y' variable to the diagnosis column.

It is worth noting that when using the 'id' feature as an index col, we get a column full of NaN entries. We remove this column as it provides no use to us. We also change some Pandas options. This is intended so that whenever we call 'head', we can see all the features and column names without truncation.

We then replace the diagnoses with 1 for malignant (original represented as an 'M') and 0 for benign (originally represented as a 'B'). This is useful for when we fit our model.
"""

from google.colab import drive

drive.mount('/content/drive')


X_full = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data.csv', index_col='id')

# Assign y to the diagnosis column
y = X_full.diagnosis

# Assigning our index_col to be the column 'id' shifted our data over, leaving a column with all NaN entries.
# We drop that here
X = X_full.drop(columns=['Unnamed: 32'])

# Show all values whenever we call head.
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
# If we run .dtypes on our data frame, we notice that all columns, aside from the diagnosis being a string, our integers.

# We replace a malignant diagnosis with 1, and benign with 0
X['diagnosis'].replace('M', 1, inplace=True)
X['diagnosis'].replace('B', 0, inplace=True)
y.replace('M', 1, inplace=True)
y.replace('B', 0, inplace=True)

print(X.shape)
print(569*31)
print(sum(y))

"""##Data Analysis

To avoide overfitting, we find the features which seem to have a low impact on the diagnosis. We do this by using a heatmap correlation chart.

The figure we get will display the correlation one attribute has on another. We are interested in which attributes do (or don't) affect the diagnosis column. We analyze the results on the figure, and ignore the features which have less than an absolute value of 0.5.
"""

# Here, we use the seaborn correlation heatmap to visualize the correlatons of features in our dataset on one another.
# Using the filter method, we will drop features which have an absolute value of less than 0.5 on the feature 'diagnosis'

# Setting up and displaying our heatmap correlation
plt.figure(figsize=(20,20))
cor = X.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds, fmt='.2f')
plt.show()

"""##Applying our Analysis

Now, we run some code to do exactly what we said we would do above: ignore the features which have a low impact on the diagnosis column.

We also split our data into training and testing data to both train and fit our model.
"""

# Keep features which have a med-high correlation on the diagnosis
features = ['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean', 
            'concave points_mean', 'radius_se', 'perimeter_se', 'area_se', 'radius_worst', 'perimeter_worst',
           'area_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst']
X = X[features]

# Break off validation set from training data
X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,
                                                      random_state=0)

"""##Creating and Testing a Model

Now we are ready to create, train, and test a model. We must use a classifying model, as the predictions are to either be a 0 (for benign) and 1 (for malignant). We assess the accuracy of this model using SKLearn's "accuracy_score" function.
"""

clf = tree.DecisionTreeClassifier()
clf = clf.fit(X_train, y_train)
preds = clf.predict(X_valid)
accuracy_score(y_valid, preds)

classes=['malignant', 'benignant']
import graphviz 
dot_data = tree.export_graphviz(clf, feature_names=features, class_names=classes, out_file=None) 
graph = graphviz.Source(dot_data) 
graph

clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(15,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
plt.plot(clf2.loss_curve_)
print(a)

"""##Agora é a sua vez

1) Por que será que a rede neural desempenhou de forma tão inferior à Árvore de Decisão? Será que há algo errado com os dados de treinamento? Consulte https://scikit-learn.org/stable/modules/neural_networks_supervised.html e verifique se está tudo certo no código acima, corrigindo eventuais problemas e verificando o novo escore de acurácia obtido.

2) Leia a documentação em https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html e adicione código para imprimir matrizes de confusão para os 2 classificadores criados anteriormente. Quais as confusões mais frequêntes para cada classificador avaliado?

3) Altere a arquitetura de sua rede neural, criando pelo menos 3 variantes com mais e com menos neurônios na camada escondida e analise os resultados obtidos em termos de acurácia no conjunto de validação. É possível tirar alguma conclusão a partir destes resultados?

**Respostas**


1)  Não há nada de errado com os dados. O uso do solver do tipo "adam" no lugar do "sgd", trás uma melhor acurácia. A descida estocástica do gradiente (SGD) atualiza os parâmetros usando o gradiente da função de perda em relação a um parâmetro que precisa de adaptação. O Adam é semelhante ao SGD no sentido de ser um otimizador estocástico, mas pode ajustar automaticamente a quantidade para atualizar parâmetros com base em estimativas adaptativas de momentos de ordem inferior. Devido a isso com o adam tivemos uma melhor acurácia]
]]
"""

from sklearn.metrics import confusion_matrix

print(pd.crosstab(y_valid,preds,rownames= ['Real'], colnames = ['Predito'],margins=True))
print('\n\n')
print(pd.crosstab(y_valid,preds2,rownames= ['Real'], colnames = ['Predito'], margins=True))

"""2) O classificador 1 confundiu em 3 casos, sendo 1 que seria maligno e o resultado foi benigno e 2 que eram benignos e foram classificados como malignos. Após a troca para o solver Adam o classificador 2 confundiu 4 casos que seriam malignos como benigno e 2 casos que seria benigno como maligno."""

clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(3,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)


clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(7,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)


clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(17,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)

clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(50,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)


clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)

clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(1500,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)

clf2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(3000,2), max_iter=1000, n_iter_no_change=10, random_state=1)
clf2 = clf2.fit(X_train, y_train)
preds2 = clf2.predict(X_valid)
a = accuracy_score(y_valid, preds2)
print(a)

"""3) É possível perceber que aumentar a quantidades de neurônios não significa aumento de acurácia, como também diminuir não representa a diminuição da acurácia.

##Questão Bonus
Escreva um código para traçar o gráfico da evolução da acurácia de modelos (árvore de decisão e rede neural multi-camada) treinados com número crescente de exemplos de treinamento (vide slide 32 da aula 06). Varie o tamanho do conjunto de treinamento de 1 a 100%, com passo de 5%. Lembre-se de selecionar de maneira aleatória os exemplos de treinamento para ponto do gráfico.
"""