# -*- coding: utf-8 -*-
"""Copy of MotionDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vrAwx3jjwKdP1Ct_KxRQDB1Ko_Fif-N4
"""

import numpy as np 
import cv2 
from google.colab.patches import cv2_imshow
!wget https://pythonprogramming.net/static/images/opencv/people-walking.mp4

cap = cv2.VideoCapture('people-walking.mp4') 

fgbg = cv2.createBackgroundSubtractorMOG2() 

#ret, BG = cap.read() 
#BG = cv2.cvtColor(BG, cv2.COLOR_BGR2GRAY)

#kernel = np.ones((5,5),np.uint8)

for i in range(5): 
    ret, frame = cap.read() 
    frame = cv2.resize(frame, None,fx=0.6,fy=0.6)

    # frame= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    fgmask = fgbg.apply(frame) 

    #fgmask = cv2.dilate(fgmask, kernel, iterations=1)

    cv2_imshow(frame) 
    cv2_imshow(fgmask)       
  
cap.release()

"""## Agora é a sua vez
Modifique o notebook acima para que implemente um modelo de *subtração adaptativa de background*, conforme visto em sala de aula.  As linhas comentadas que contém *BG e cv2.cvtColor* dão um pontapé inicial nesta direção.  Lembre-se de remover as linhas que utilizam o modelo de subtração de background MOG2.

### ***Atividade Bonus***
Utilize morfologia matemática (erosão e dilatação) para filtrar os ruídos de background e melhorar a definição da área dos objetos em movimento.  Há 2 linhas comentadas no código (*kernel = np.opes*, *cv2.dilate*) que tratam da melhoria da definição dos objetos em movimento, mas não trata o ruído de background. Veja como pode melhorar a imagem segmentada de uma forma geral.

Resposta:
"""

cap = cv2.VideoCapture('people-walking.mp4') 

alpha = 0.001
ret, BG = cap.read() 
BG = cv2.cvtColor(BG, cv2.COLOR_BGR2GRAY)

#kernel = np.ones((5,5),np.uint8)

for i in range(5): 
    ret, frame = cap.read() 
    #frame = cv2.resize(frame, None,fx=0.6,fy=0.6)
    f = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    diff = cv2.absdiff(f.astype(np.uint8),BG.astype(np.uint8))

    ret,mask = cv2.threshold(diff,15,255,cv2.THRESH_BINARY)

    BG = f * alpha + BG * (1-alpha)

    #fgmask = cv2.dilate(fgmask, kernel, iterations=1)

    cv2_imshow(BG) 
    cv2_imshow(mask)

"""Bônus:"""

cap = cv2.VideoCapture('people-walking.mp4') 

alpha = 0.001
ret, BG = cap.read() 
BG = cv2.cvtColor(BG, cv2.COLOR_BGR2GRAY)

kernel = np.ones((1,1),np.uint8)

kernel2 = np.ones((2,2),np.uint8)

for i in range(5): 
    ret, frame = cap.read() 
    #frame = cv2.resize(frame, None,fx=0.6,fy=0.6)
    f = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    diff = cv2.absdiff(f.astype(np.uint8),BG.astype(np.uint8))

    ret,mask = cv2.threshold(diff,15,255,cv2.THRESH_BINARY)

    BG = f * alpha + BG * (1-alpha)

    mask = cv2.dilate(mask, kernel, iterations=1)

    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel2)

    cv2_imshow(BG) 
    cv2_imshow(mask)